
<html>
<head>

<title>Warp-Based Video Motion Magnification for Revealing Subtle Changes</title>
<meta name="author" content="Yunfei Shi" >
<meta name="keywords" content="Video Motion Magnification, Image Deformation">
<meta name="description" content="Video Motion Magnification">
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8">
<meta http-equiv="content-style-type" content="text/css">
<meta http-equiv="expires" content="0">

<style type="text/css">

	a:link       { color: #0000C0; text-decoration=none }
	a:visited    { color: #0000C0; text-decoration=none }
	a:active     { color: #0000FF; text-decoration=none }
	a:hover      { color: #0080FF; text-decoration=none }

	body {
				font-family: arial, helvetica, sans-serif; font-size: 11pt;
				margin: 80px;
				margin-top:    70px;
				margin-bottom: 70px;
	}

	h1 { font-size: 200%; margin-top 20px;margin-bottom: 20px; }
	h2 { font-size: 150%;margin-top: 60px;margin-bottom: 10px;}
	h3 { font-size: 100%; margin-top: 20px; margin-bottom: 10px;}
	p  { margin-top: 0em; margin-bottom: 5px  }

</style>
</head>

<body>
<div align="left" >
  <h2 align="center"><strong>Warp-Based Video Motion Magnification for Revealing Subtle Changes</strong></h2>
	<p align="center">
		<sup>1</sup><a href="https://github.com/AFEICHINA"/>Yunfei Shi</a>&nbsp;&nbsp;
		<sup>1</sup><a href="hzy@hzy.org.cn"/>Zhiyong Huang</a>&nbsp;&nbsp;
		<sup>1</sup><a href="yirongwu@gmail.com"/>Yirong Wu</a>&nbsp;&nbsp;
		<sup>1,2</sup><a href="watersun1977@hotmail.com"/>Shuifa Sun</a>*&nbsp;&nbsp;
		<sup>1</sup><a href="fmdong@ctgu.edu.cn">Fangmin Dong</a>&nbsp;&nbsp;
	</p>
	<p align="center">
		<sup>1</sup>College of Computer and Information Technology,China Three Gorges University, Yichang, Hubei, P.R.China&nbsp;&nbsp;&nbsp;&nbsp;
		<sup>2</sup>Department of Electrical Engineering and Computer Science,University of Wisconsin-Milwaukee, Milwaukee, USA&nbsp;&nbsp;&nbsp;&nbsp;
	</p>
	</br></br>
	<p align="center"><img src="./imgs/1.png" alt=""/></p></br>

	<p align="center">Figure 1: Baby sequence and its amplification (from left) above, the method based on phase, the method based on the deep learning and the method based on image warping (this paper). For each of the amplified sequence, the location of the red line and blue line show time slice (the following), the method based on image deformation reduces the artifacts and noise, the effect and the depth of learning is closest to, and even in every frame image quality is more similar to the original image.
	</p>

  <h2>Abstract</h2>
	<p align="justify">We present a warp-based video motion magnification, in which only one-frame latency is maintained. Video motion magnification can amplify subtle motions and even reveal small color changes in video sequences. Current techniques analayz the signals of each pixel over time in differtent spatial scales and orientations, which inevitably amplifies the noise and results in ringing artifacts in video. The start-of-the-art techniques relying on filters by learning also have excessive blurring in images. In this paper, we propose a simple Lagrangian technique, which involves image deformation and optical flow. We achieve motion magnification by warping the frame in video, which is guided by feature points and only uses motions from the past, keeping the original video details without amplifying noise at the same time. In this way, the proposed method can work online in real time. Experimental results show that our method can achieve high-quality results and significantly reduce artifacts while comparing to the state-of-the-art.
	</p>
	</br>
	</br>
	<p align="center"><img src="./imgs/2.png" alt=""/></p></br>
	</br>
	<p align="center">
		Figure 2:Our warp-based approach manipulates motion in videos by tracking featrue points and warpping the images. The method proposed in this paper calculates feature points in the first frame of the video and tracks these feature points in subsequent frame sequences. For some video sequences, tracking feature points in the ROI area gives better results.
	</p> 

	</br>

<h2>Introduction</h2>
	<p align="justify">Leveraging current Lagrangian based techniques,we propose a warp-based video motion magnificationin in this paper. We assumed that the reasonable deformation creat similar effects as subtle motion in each frame. Our method does not need a lot of manual intervention, but only a few of feature points that need to be tracked, then it warps the frame to realize motion magnification without amplifying noise. Moreover, it doesn’t need to design filters, which preserves all the details in video to the greatest extent. The main contributions of this paper are as follows: 1)We present a simplified Lagrangian subtle motion magnification, which barely needs manual intervention. 2)The ”as-similar-as-possible” approach is applied to motion amplification. 3)Foreground separation and texture synthesis are used in our magnification to improve the details.
	</p>
	<p align="center"><img src="./imgs/5.png" alt=""/></p></br>
	</br>
	<p align="center">
		Figure 3:Image quality comparison. (b, c, d) is the baby magnification sequence (magnification 20 times), phase-based method shows more ringing artifacts and blurring, and the learning-based method is blurring at the details. Our method proposed in this paper is better. The image details are preserved and there is no magnification noise.
	</p>
	<p align="center"><img src="./imgs/4.png" alt=""/></p></br>
	</br>
	<p align="center">
		Figure 4:(a) The phase-based approach uses spatial decomposition filters and time filters to show severe ringing artifacts; (b) Learningbased methods learn spatial decomposition filters directly from image frames, in static better edges and fewer ringing artifacts can be obtained in the static mode; (c) We do not use spatial and temporal filters and can obtain the results of the approximate when comparing with the learning-based method.
	</p>
	
<h2>Video</h2>
</br>
	</br>
	<div align="center">
	<!--<iframe width="560" height="315" src="https://www.youtube.com/embed/G8RbuKI_784?rel=0&amp;controls=0&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>-->
	<video style="width:640;height:auto" muted loop controls>
		<source src="files/submissionVideo.mp4" type="video/mp4">
	</video>
	</div>
	</br>
	<p align="center">
	By setting different bandwidth and position for DoG filter, we show that DoG based FBE model is able to realize selective segmentation, that is, to segment different part in the same image.
</p>
</br>



<h2>Source Code</h2>

Source Code (Matlab) and Models:
[ <a href="#">Demo</a> ]


<h2>Citation - BibTeX</h2>
<p align="justify">
	<b>Warp-Based Video Motion Magnification for Revealing Subtle Changes</b>
	<br/>
		Yunfei Shi, Zhiyong Huang, Yirong Wu, Shuifa Sun, Fangmin Dong. Warp-Based Video Motion Magnification for Revealing Subtle Changes
	<br/>
	<i> </i>.<br/>
	[ <a href="#">PDF</a> ]
	[ <a href="#">BibTeX</a> ]
</p>

<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=8914677;
var sc_invisible=1;
var sc_security="f1edf88a";
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="web analytics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="http://c.statcounter.com/8914677/0/f1edf88a/1/"
alt="web analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
</body>
</html>

